{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princesinha24/Liver_class/blob/master/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X7fxY9iBR0e"
      },
      "source": [
        "# importing all necessary libraries\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision\r\n",
        "from torchsummary import summary\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyNmzVdEBmmL",
        "outputId": "5ab937c8-9a11-4bae-90d4-49ec1af9cee7"
      },
      "source": [
        "#defining device\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4khAkCsDBthn"
      },
      "source": [
        "# Define AlexNet network structure\r\n",
        "class Alex(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Alex, self).__init__()\r\n",
        "        self.layer1 = nn.Sequential( \r\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4), # 96*54*54\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 96*27*27\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.BatchNorm2d(num_features= 96),\r\n",
        "            )\r\n",
        "        self.layer2 = nn.Sequential(\r\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # 256*27*27\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 256*13*13\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.BatchNorm2d(num_features= 256),\r\n",
        "            )\r\n",
        "        self.layer3 = nn.Sequential(\r\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # 384*13*13\r\n",
        "            )\r\n",
        "        self.layer4 = nn.Sequential(\r\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # 384*13*13\r\n",
        "            )\r\n",
        " \r\n",
        "        self.layer5 = nn.Sequential(\r\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # 256*13*13\r\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), # 256*6*6\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.BatchNorm2d(num_features= 256),\r\n",
        "            )\r\n",
        "        self.fc1 = nn.Linear(256*5*5, 1024)\r\n",
        "        self.fc2 = nn.Linear(1024, 512)\r\n",
        "        self.fc3 = nn.Linear(512, 4)\r\n",
        " \r\n",
        "    def forward(self, x):\r\n",
        "        x = self.layer1(x)\r\n",
        "        x = self.layer2(x)\r\n",
        "        x = self.layer3(x)\r\n",
        "        x = self.layer4(x)\r\n",
        "        x = self.layer5(x)\r\n",
        "        x = x.view(-1, 256*5*5)\r\n",
        "        x = self.fc1(x)\r\n",
        "        x = self.fc2(x)\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFqmle2GFlHY",
        "outputId": "2b6c61dc-4ca7-4b98-cb0f-39077bdbccb1"
      },
      "source": [
        "#summary of network\r\n",
        "model = Alex().to(device)\r\n",
        "summary(model,(3,224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 96, 54, 54]          34,944\n",
            "         MaxPool2d-2           [-1, 96, 26, 26]               0\n",
            "              ReLU-3           [-1, 96, 26, 26]               0\n",
            "       BatchNorm2d-4           [-1, 96, 26, 26]             192\n",
            "            Conv2d-5          [-1, 256, 26, 26]         614,656\n",
            "         MaxPool2d-6          [-1, 256, 12, 12]               0\n",
            "              ReLU-7          [-1, 256, 12, 12]               0\n",
            "       BatchNorm2d-8          [-1, 256, 12, 12]             512\n",
            "            Conv2d-9          [-1, 384, 12, 12]         885,120\n",
            "           Conv2d-10          [-1, 384, 12, 12]       1,327,488\n",
            "           Conv2d-11          [-1, 256, 12, 12]         884,992\n",
            "        MaxPool2d-12            [-1, 256, 5, 5]               0\n",
            "             ReLU-13            [-1, 256, 5, 5]               0\n",
            "      BatchNorm2d-14            [-1, 256, 5, 5]             512\n",
            "           Linear-15                 [-1, 1024]       6,554,624\n",
            "           Linear-16                  [-1, 512]         524,800\n",
            "           Linear-17                    [-1, 4]           2,052\n",
            "================================================================\n",
            "Total params: 10,829,892\n",
            "Trainable params: 10,829,892\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 7.07\n",
            "Params size (MB): 41.31\n",
            "Estimated Total Size (MB): 48.96\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0_6YtgLFpIH",
        "outputId": "976ec7c7-bac8-4848-8f2f-c56f7ed547e3"
      },
      "source": [
        "!pip install pkbar\r\n",
        "import pkbar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pkbar in /usr/local/lib/python3.6/dist-packages (0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pkbar) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXHzHKE5KWos"
      },
      "source": [
        "batch_size= 32\r\n",
        "device = 'cuda'\r\n",
        "num_classes= 4\r\n",
        "input_shape=(3,224,224)\r\n",
        "learning_rate=0.001\r\n",
        "num_epochs= 30\r\n",
        "load_model=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzESOdeTc9Q7"
      },
      "source": [
        "#loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK61nkdNKY93",
        "outputId": "7d7212d7-f889-404b-d65c-68c1fa5921fd"
      },
      "source": [
        "main_path= 'drive/MyDrive/KMC Dataset'\r\n",
        "train_dir= os.path.join(main_path,'Training')\r\n",
        "test_dir= os.path.join(main_path,'Test')\r\n",
        "val_dir= os.path.join(main_path,'Validation')\r\n",
        "\r\n",
        "check_pt_file= os.path.join(main_path, 'AlexNet.pth.tar')\r\n",
        "\r\n",
        "print(os.listdir(main_path))\r\n",
        "print(os.listdir(train_dir))\r\n",
        "print(os.listdir(test_dir))\r\n",
        "print(os.listdir(val_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AlexNet.ipynb', 'Training', 'Validation', 'Test', 'ResNet50_Checkpoint_1.pth.tar', 'ResNet50.ipynb', 'DenseNet.ipynb', 'AlexNet_checkpoint.pth.tar']\n",
            "['grade1', 'grade3', 'grade2', 'grade0']\n",
            "['grade1', 'grade0', 'grade2', 'grade3']\n",
            "['grade2', 'grade1', 'grade0', 'grade3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD-qbVPxKm0i"
      },
      "source": [
        "train_data= datasets.ImageFolder(train_dir, transform= transforms.ToTensor())\r\n",
        "test_data= datasets.ImageFolder(test_dir, transform= transforms.ToTensor())\r\n",
        "val_data= datasets.ImageFolder(val_dir, transform= transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4Opdt5BYWgU"
      },
      "source": [
        "train_loader= DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader= DataLoader(test_data, batch_size=batch_size, shuffle=True)\r\n",
        "val_loader= DataLoader(val_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojTQO-3EYlB6",
        "outputId": "8987ead0-466b-427d-d6d8-b805d348040f"
      },
      "source": [
        "train_data.class_to_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'grade0': 0, 'grade1': 1, 'grade2': 2, 'grade3': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCtPk7qnP_qC"
      },
      "source": [
        "def save_checkpoint(state,filename=\"drive/MyDrive/KMC Dataset/AlexNet_checkpoint.pth.tar\"):\r\n",
        "  torch.save(state,filename)\r\n",
        "  print(\"save checkpoint\")\r\n",
        "def load_checkpoint(checkpoint):\r\n",
        "  model.load_state_dict(checkpoint['state_dict'])\r\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\r\n",
        "  print(\"load check point\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaHbn6ecQH5S",
        "outputId": "a718d3cf-32a1-4f03-a4f9-e33c41a28db0"
      },
      "source": [
        "if load_model:\r\n",
        "  load_checkpoint(torch.load(\"drive/MyDrive/KMC Dataset/AlexNet_checkpoint.pth.tar\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load check point\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2LMG-5XYnpL",
        "outputId": "2010d448-e55a-4276-daff-e9e3c3f6f7d4"
      },
      "source": [
        "# Train Network\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    x=0\r\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\r\n",
        "        # Get data to cuda if possible\r\n",
        "        data = data.to(device=device)\r\n",
        "        targets = targets.to(device=device)\r\n",
        "\r\n",
        "        # forward\r\n",
        "        scores = model(data)\r\n",
        "        loss = criterion(scores, targets)\r\n",
        "        x+=loss\r\n",
        "        #print(batch_idx,loss)\r\n",
        "        # backward\r\n",
        "        optimizer.zero_grad()\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # gradient descent or adam step\r\n",
        "        optimizer.step()\r\n",
        "    print('epoch no',epoch,\"loss\",x/batch_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch no 0 loss tensor(0.1694, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 1 loss tensor(1.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 2 loss tensor(4.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 3 loss tensor(0.5844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 4 loss tensor(0.4886, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 5 loss tensor(0.8866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 6 loss tensor(0.3036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 7 loss tensor(0.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 8 loss tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 9 loss tensor(0.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 10 loss tensor(1.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 11 loss tensor(0.2250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 12 loss tensor(0.5722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 13 loss tensor(0.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 14 loss tensor(0.3355, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 15 loss tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 16 loss tensor(0.1011, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 17 loss tensor(0.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 18 loss tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 19 loss tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 20 loss tensor(0.4534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 21 loss tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 22 loss tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 23 loss tensor(0.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 24 loss tensor(0.1314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 25 loss tensor(0.0587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 26 loss tensor(0.0750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 27 loss tensor(0.0526, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 28 loss tensor(0.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch no 29 loss tensor(0.0283, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smCP0uqsQXhp",
        "outputId": "d1f14a1b-7386-4a4f-c91d-294e95e7859c"
      },
      "source": [
        "checkpoint={'state_dict':model.state_dict(),'optimizer':optimizer.state_dict()}\r\n",
        "save_checkpoint(checkpoint)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "save checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfB9IuyDYw2K"
      },
      "source": [
        "#check accuracy and create confussion matrix\r\n",
        "def check_accuracy(loader, model):\r\n",
        "    #confusion matrix\r\n",
        "    con=np.zeros([4,4],dtype=np.long)\r\n",
        "    print(\"Checking accuracy on data\")\r\n",
        "\r\n",
        "    num_correct = 0\r\n",
        "    num_samples = 0\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "        for x, y in loader:\r\n",
        "            x = x.to(device=device)\r\n",
        "            y = y.to(device=device)\r\n",
        "\r\n",
        "            scores = model(x)\r\n",
        "            _, predictions = scores.max(1)\r\n",
        "            #print (predictions,y)\r\n",
        "            for i in range(y.size(0)):\r\n",
        "              con[predictions[i]][y[i]]+=1\r\n",
        "            num_correct += (predictions == y).sum()\r\n",
        "            num_samples += predictions.size(0)\r\n",
        "        print (con)\r\n",
        "        print(\r\n",
        "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\r\n",
        "        )\r\n",
        "\r\n",
        "    model.train()\r\n",
        "    return con"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FA7AA-LkC3M",
        "outputId": "69f93793-fddd-4d8d-ff41-e528906f6780"
      },
      "source": [
        "con_train=check_accuracy(train_loader, model)\r\n",
        "con_test=check_accuracy(test_loader, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking accuracy on data\n",
            "[[672   0   0   0]\n",
            " [  0 610   0   0]\n",
            " [  0  30 670   0]\n",
            " [  0   0   0 665]]\n",
            "Got 2617 / 2647 with accuracy 98.87\n",
            "Checking accuracy on data\n",
            "[[69  0  0  0]\n",
            " [ 0 65  4  2]\n",
            " [ 1 15 76  8]\n",
            " [ 0  0  0 40]]\n",
            "Got 250 / 280 with accuracy 89.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTDVuvbwkEsE"
      },
      "source": [
        "def precision_recall_f1(confusion_matrix):\r\n",
        "  num_classes= confusion_matrix.shape[0]\r\n",
        "  precision= np.zeros(num_classes, np.float64)\r\n",
        "  recall= np.zeros(num_classes, np.float64)\r\n",
        "  f1= np.zeros(num_classes, np.float64)\r\n",
        "\r\n",
        "  for i in range(num_classes):\r\n",
        "    precision[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[i])\r\n",
        "    recall[i]= confusion_matrix[i,i]/np.sum(confusion_matrix[:,i])\r\n",
        "    f1[i]= 2*precision[i]*recall[i]/(precision[i]+recall[i])\r\n",
        "\r\n",
        "  return precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VzPnTnUzl2H",
        "outputId": "04de0c9b-2a3e-4b1f-f210-56439e45d867"
      },
      "source": [
        "precision, recall, f1= precision_recall_f1(con_test)\r\n",
        "print(precision,recall,f1,sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         0.91549296 0.76       1.        ]\n",
            "[0.98571429 0.8125     0.95       0.8       ]\n",
            "[0.99280576 0.86092715 0.84444444 0.88888889]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cgXkn5nzmq3",
        "outputId": "f5ffd909-720e-460a-9539-bdc8033da9dc"
      },
      "source": [
        "print(\"Precision:\",np.mean(precision))\r\n",
        "print(\"Recall:\",np.mean(recall))\r\n",
        "print(\"F1 score:\",np.mean(f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.9188732394366197\n",
            "Recall: 0.8870535714285714\n",
            "F1 score: 0.8967665602617244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcOqRxDWzpRn",
        "outputId": "d3f245c2-9730-4fa9-f8ff-5d5cb66ebc8c"
      },
      "source": [
        "iterator2= iter(test_loader)\r\n",
        "t2 = next(iterator2)\r\n",
        "images, labels= t2\r\n",
        "\r\n",
        "model.eval()\r\n",
        "scores= model(images.to(device=device))\r\n",
        "\r\n",
        "plt.figure(figsize=(20,5))\r\n",
        "for r in range(0,20):\r\n",
        "    plt.subplot(2,10,r+1)\r\n",
        "    f= plt.imshow(images[r,0],cmap='gray')\r\n",
        "    plt.title(int((scores.max(1))[1][r]))\r\n",
        "    print('Expected',int(labels[r]),'Got',int((scores.max(1))[1][r]),end=' | ')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Expected 2 Got 2 | Expected 1 Got 1 | Expected 1 Got 1 | Expected 1 Got 1 | Expected 0 Got 0 | Expected 2 Got 1 | Expected 2 Got 2 | Expected 0 Got 0 | Expected 2 Got 2 | Expected 0 Got 0 | Expected 2 Got 2 | Expected 0 Got 0 | Expected 1 Got 1 | Expected 0 Got 0 | Expected 2 Got 2 | Expected 0 Got 0 | Expected 2 Got 2 | Expected 0 Got 0 | Expected 0 Got 0 | Expected 3 Got 3 | "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6MLdiiIzw3-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}